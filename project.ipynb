{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Code for making a basic image classifier from scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is only to get you started with a code sample of a simple classifier built from scratch. The data on which models in this notebook are train are not provided. Hence, the output is given. You need not run the cells to see the output. If you choose to do so with your own training and testing dataset, you might not get the same accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCLAIMER: These models are not the best classifiers, they may perform very moderately on other data, the goal is to get new students started with the basic code required to build classifiers from scratch. Also, many more modifications may be implemented in terms of model architecture, data augmentation and other techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those who are new to this field, the first step is making a simple Densly connected neural network and training it with the data extracted from google images.\n",
    "\n",
    "This is shown in the following cell, you can change the layers/architecture etc. to see if the accuracy increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 6.2706 - accuracy: 0.4727 - val_loss: 3.1323 - val_accuracy: 0.4844\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 2.2030 - accuracy: 0.5195 - val_loss: 1.5041 - val_accuracy: 0.5312\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.6055 - accuracy: 0.4883 - val_loss: 1.0742 - val_accuracy: 0.5625\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.1651 - accuracy: 0.5117 - val_loss: 1.7158 - val_accuracy: 0.4844\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 1.3062 - accuracy: 0.5664 - val_loss: 1.7494 - val_accuracy: 0.4844\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 1.0671 - accuracy: 0.5547 - val_loss: 1.0123 - val_accuracy: 0.5625\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 0.8387 - accuracy: 0.5820 - val_loss: 0.6953 - val_accuracy: 0.6562\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.8533 - accuracy: 0.6094 - val_loss: 1.0579 - val_accuracy: 0.4844\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.9174 - accuracy: 0.6602 - val_loss: 0.9649 - val_accuracy: 0.4844\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.7389 - accuracy: 0.6523 - val_loss: 0.6622 - val_accuracy: 0.6719\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.5632 - accuracy: 0.7383 - val_loss: 1.0197 - val_accuracy: 0.5312\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.4655 - accuracy: 0.7773 - val_loss: 0.7580 - val_accuracy: 0.6406\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.3933 - accuracy: 0.8047 - val_loss: 0.6939 - val_accuracy: 0.6094\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.4279 - accuracy: 0.8008 - val_loss: 0.8255 - val_accuracy: 0.6719\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.4940 - accuracy: 0.7422 - val_loss: 0.6804 - val_accuracy: 0.6562\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.4070 - accuracy: 0.7891 - val_loss: 0.8543 - val_accuracy: 0.6719\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.4578 - accuracy: 0.7578 - val_loss: 0.6871 - val_accuracy: 0.6406\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.3452 - accuracy: 0.8516 - val_loss: 0.6964 - val_accuracy: 0.6719\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 0.3468 - accuracy: 0.8555 - val_loss: 0.7042 - val_accuracy: 0.6719\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 43ms/step - loss: 0.3647 - accuracy: 0.8281 - val_loss: 0.7517 - val_accuracy: 0.6094\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9466 - accuracy: 0.5250\n",
      "Test Accuracy: 0.5249999761581421\n"
     ]
    }
   ],
   "source": [
    "# Try a simple Neural Network\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the data\n",
    "def load_and_preprocess_data(cat_path, dog_path, target_size=(150, 150)):\n",
    "    cat_images = [cv2.resize(cv2.imread(os.path.join(cat_path, f)), target_size) for f in os.listdir(cat_path)]\n",
    "    dog_images = [cv2.resize(cv2.imread(os.path.join(dog_path, f)), target_size) for f in os.listdir(dog_path)]\n",
    "\n",
    "    # Convert images to numpy arrays\n",
    "    cat_data = np.array(cat_images)\n",
    "    dog_data = np.array(dog_images)\n",
    "\n",
    "    # Create labels (0 for cats, 1 for dogs)\n",
    "    cat_labels = np.zeros(len(cat_data))\n",
    "    dog_labels = np.ones(len(dog_data))\n",
    "\n",
    "    # Concatenate data and labels\n",
    "    data = np.concatenate((cat_data, dog_data))\n",
    "    labels = np.concatenate((cat_labels, dog_labels))\n",
    "\n",
    "    # Normalize pixel values to the range [0, 1]\n",
    "    data = data / 255.0\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "# Set paths to your cat and dog image folders\n",
    "cat_path = 'Dataset/elephant'\n",
    "dog_path = 'Dataset/horse'\n",
    "\n",
    "# Load and preprocess data\n",
    "data, labels = load_and_preprocess_data(cat_path, dog_path)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    data, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "target_size = [150,150]\n",
    "\n",
    "# Build the model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(target_size[0], target_size[1], 3)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_data, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output:\n",
    "\n",
    "Epoch 1/20\n",
    "\n",
    "8/8 [==============================] - 1s 66ms/step - loss: 6.2706 - accuracy: 0.4727 - val_loss: 3.1323 - val_accuracy: 0.4844\n",
    "\n",
    "Epoch 2/20\n",
    "\n",
    "8/8 [==============================] - 0s 46ms/step - loss: 2.2030 - accuracy: 0.5195 - val_loss: 1.5041 - val_accuracy: 0.5312\n",
    "\n",
    "Epoch 3/20\n",
    "\n",
    "8/8 [==============================] - 0s 50ms/step - loss: 1.6055 - accuracy: 0.4883 - val_loss: 1.0742 - val_accuracy: 0.5625\n",
    "\n",
    "Epoch 4/20\n",
    "\n",
    "8/8 [==============================] - 0s 48ms/step - loss: 1.1651 - accuracy: 0.5117 - val_loss: 1.7158 - val_accuracy: 0.4844\n",
    "\n",
    "Epoch 5/20\n",
    "\n",
    "8/8 [==============================] - 0s 46ms/step - loss: 1.3062 - accuracy: 0.5664 - val_loss: 1.7494 - val_accuracy: 0.4844\n",
    "\n",
    "Epoch 6/20\n",
    "\n",
    "8/8 [==============================] - 0s 44ms/step - loss: 1.0671 - accuracy: 0.5547 - val_loss: 1.0123 - val_accuracy: 0.5625\n",
    "\n",
    "Epoch 7/20\n",
    "\n",
    "8/8 [==============================] - 0s 44ms/step - loss: 0.8387 - accuracy: 0.5820 - val_loss: 0.6953 - val_accuracy: 0.6562\n",
    "\n",
    "Epoch 8/20\n",
    "\n",
    "8/8 [==============================] - 0s 45ms/step - loss: 0.8533 - accuracy: 0.6094 - val_loss: 1.0579 - val_accuracy: 0.4844\n",
    "\n",
    "Epoch 9/20\n",
    "\n",
    "8/8 [==============================] - 0s 45ms/step - loss: 0.9174 - accuracy: 0.6602 - val_loss: 0.9649 - val_accuracy: 0.4844\n",
    "\n",
    "Epoch 10/20\n",
    "\n",
    "8/8 [==============================] - 0s 46ms/step - loss: 0.7389 - accuracy: 0.6523 - val_loss: 0.6622 - val_accuracy: 0.6719\n",
    "\n",
    "...\n",
    "\n",
    "Epoch 20/20\n",
    "\n",
    "8/8 [==============================] - 0s 43ms/step - loss: 0.3647 - accuracy: 0.8281 - val_loss: 0.7517 - val_accuracy: 0.6094\n",
    "\n",
    "3/3 [==============================] - 0s 5ms/step - loss: 0.9466 - accuracy: 0.5250\n",
    "\n",
    "Test Accuracy: 0.5249999761581421"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN (Convolutional Neural Networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've tried using a simple densely connected Neural Network, you should use CNNs (Convolutional Neural Networks), these are widely used as the base of several simple image classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "8/8 [==============================] - 3s 247ms/step - loss: 0.8998 - accuracy: 0.5000 - val_loss: 0.7213 - val_accuracy: 0.4844\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.6930 - accuracy: 0.5586 - val_loss: 0.6915 - val_accuracy: 0.4844\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.6928 - accuracy: 0.5547 - val_loss: 0.6855 - val_accuracy: 0.5469\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.6572 - accuracy: 0.5977 - val_loss: 0.7093 - val_accuracy: 0.4688\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.5845 - accuracy: 0.6797 - val_loss: 0.7011 - val_accuracy: 0.5469\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.5682 - accuracy: 0.6641 - val_loss: 0.5912 - val_accuracy: 0.6406\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.5125 - accuracy: 0.7500 - val_loss: 0.6445 - val_accuracy: 0.6719\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.5040 - accuracy: 0.7461 - val_loss: 0.5651 - val_accuracy: 0.6406\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.4588 - accuracy: 0.7891 - val_loss: 0.5941 - val_accuracy: 0.5781\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.4383 - accuracy: 0.7891 - val_loss: 0.5118 - val_accuracy: 0.7031\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.4093 - accuracy: 0.8047 - val_loss: 0.4836 - val_accuracy: 0.7812\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.2999 - accuracy: 0.8945 - val_loss: 0.5517 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.2798 - accuracy: 0.9023 - val_loss: 0.4620 - val_accuracy: 0.8125\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.2539 - accuracy: 0.9023 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.1493 - accuracy: 0.9531 - val_loss: 0.5522 - val_accuracy: 0.8281\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.1022 - accuracy: 0.9766 - val_loss: 0.5571 - val_accuracy: 0.7969\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.0633 - accuracy: 0.9883 - val_loss: 0.5394 - val_accuracy: 0.8281\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 2s 238ms/step - loss: 0.0386 - accuracy: 0.9922 - val_loss: 0.7225 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 2s 263ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.6393 - val_accuracy: 0.7969\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 2s 260ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.6761 - val_accuracy: 0.8281\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 2s 254ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.8716 - val_accuracy: 0.8281\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 2s 259ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.9721 - val_accuracy: 0.8281\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 2s 260ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0046 - val_accuracy: 0.7969\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 2s 257ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0400 - val_accuracy: 0.7969\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 2s 259ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.0746 - val_accuracy: 0.7812\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 2s 256ms/step - loss: 8.6256e-04 - accuracy: 1.0000 - val_loss: 1.1065 - val_accuracy: 0.7969\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 2s 257ms/step - loss: 7.3541e-04 - accuracy: 1.0000 - val_loss: 1.1390 - val_accuracy: 0.7812\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 2s 255ms/step - loss: 6.4870e-04 - accuracy: 1.0000 - val_loss: 1.1482 - val_accuracy: 0.7969\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 2s 255ms/step - loss: 5.8564e-04 - accuracy: 1.0000 - val_loss: 1.1592 - val_accuracy: 0.7969\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 2s 255ms/step - loss: 5.2710e-04 - accuracy: 1.0000 - val_loss: 1.1712 - val_accuracy: 0.7969\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 2.1892 - accuracy: 0.7125\n",
      "Test Accuracy: 0.7124999761581421\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the data\n",
    "def load_and_preprocess_data(cat_path, dog_path, target_size=(150, 150)):\n",
    "    cat_images = [cv2.resize(cv2.imread(os.path.join(cat_path, f)), target_size) for f in os.listdir(cat_path)]\n",
    "    dog_images = [cv2.resize(cv2.imread(os.path.join(dog_path, f)), target_size) for f in os.listdir(dog_path)]\n",
    "\n",
    "    # Convert images to numpy arrays\n",
    "    cat_data = np.array(cat_images)\n",
    "    dog_data = np.array(dog_images)\n",
    "\n",
    "    # Create labels (0 for cats, 1 for dogs)\n",
    "    cat_labels = np.zeros(len(cat_data))\n",
    "    dog_labels = np.ones(len(dog_data))\n",
    "\n",
    "    # Concatenate data and labels\n",
    "    data = np.concatenate((cat_data, dog_data))\n",
    "    labels = np.concatenate((cat_labels, dog_labels))\n",
    "\n",
    "    # Normalize pixel values to the range [0, 1]\n",
    "    data = data / 255.0\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "# Set paths to your cat and dog image folders\n",
    "cat_path = 'Dataset/elephant'\n",
    "dog_path = 'Dataset/horse'\n",
    "\n",
    "# Load and preprocess data\n",
    "data, labels = load_and_preprocess_data(cat_path, dog_path)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    data, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "target_size = [150,150]\n",
    "\n",
    "# Build a CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(target_size[0], target_size[1], 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_data, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output\n",
    "\n",
    "Epoch 1/30\n",
    "\n",
    "8/8 [==============================] - 3s 247ms/step - loss: 0.8998 - accuracy: 0.5000 - val_loss: 0.7213 - val_accuracy: 0.4844\n",
    "\n",
    "Epoch 2/30\n",
    "\n",
    "8/8 [==============================] - 2s 226ms/step - loss: 0.6930 - accuracy: 0.5586 - val_loss: 0.6915 - val_accuracy: 0.4844\n",
    "\n",
    "Epoch 3/30\n",
    "\n",
    "8/8 [==============================] - 2s 224ms/step - loss: 0.6928 - accuracy: 0.5547 - val_loss: 0.6855 - val_accuracy: 0.5469\n",
    "\n",
    "...\n",
    "\n",
    "Epoch 30/30\n",
    "\n",
    "8/8 [==============================] - 2s 255ms/step - loss: 5.2710e-04 - accuracy: 1.0000 - val_loss: 1.1712 - val_accuracy: 0.7969\n",
    "\n",
    "3/3 [==============================] - 0s 53ms/step - loss: 2.1892 - accuracy: 0.7125\n",
    "\n",
    "Test Accuracy: 0.7124999761581421"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase the accuracy further, we must augment the data, ie; change the training data (such that the original subject of use is still meaningful). This involves zooming in/out, horizontal flipping, rotation etc. This helps the model learn modifications that it might encounter ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 1.2988 - accuracy: 0.5969 - val_loss: 0.7283 - val_accuracy: 0.6000\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 3s 262ms/step - loss: 0.6696 - accuracy: 0.5625 - val_loss: 0.7129 - val_accuracy: 0.4625\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 0.6564 - accuracy: 0.5406 - val_loss: 0.7108 - val_accuracy: 0.4750\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 0.6581 - accuracy: 0.5594 - val_loss: 0.6827 - val_accuracy: 0.5750\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 3s 262ms/step - loss: 0.6501 - accuracy: 0.6531 - val_loss: 0.6808 - val_accuracy: 0.5750\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 3s 263ms/step - loss: 0.6185 - accuracy: 0.6438 - val_loss: 0.7264 - val_accuracy: 0.6000\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 3s 262ms/step - loss: 0.6016 - accuracy: 0.6562 - val_loss: 0.6720 - val_accuracy: 0.6250\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 3s 263ms/step - loss: 0.5984 - accuracy: 0.6812 - val_loss: 0.6041 - val_accuracy: 0.6000\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.5774 - accuracy: 0.6500 - val_loss: 0.6467 - val_accuracy: 0.6125\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.5822 - accuracy: 0.6938 - val_loss: 0.6642 - val_accuracy: 0.6500\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.5467 - accuracy: 0.7031 - val_loss: 0.6188 - val_accuracy: 0.6500\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 0.5569 - accuracy: 0.6906 - val_loss: 0.6323 - val_accuracy: 0.5875\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.5088 - accuracy: 0.7594 - val_loss: 0.7550 - val_accuracy: 0.6250\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.5704 - accuracy: 0.6875 - val_loss: 0.5902 - val_accuracy: 0.6875\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.5123 - accuracy: 0.7500 - val_loss: 0.6187 - val_accuracy: 0.7250\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.5033 - accuracy: 0.7500 - val_loss: 0.6082 - val_accuracy: 0.6625\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 3s 296ms/step - loss: 0.4826 - accuracy: 0.7531 - val_loss: 0.5775 - val_accuracy: 0.7250\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.5029 - accuracy: 0.7437 - val_loss: 0.5865 - val_accuracy: 0.6875\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.4662 - accuracy: 0.7719 - val_loss: 0.6529 - val_accuracy: 0.6750\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.4875 - accuracy: 0.7969 - val_loss: 0.5414 - val_accuracy: 0.7625\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.4268 - accuracy: 0.8125 - val_loss: 0.6134 - val_accuracy: 0.7375\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.4793 - accuracy: 0.7656 - val_loss: 0.5682 - val_accuracy: 0.7375\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.4530 - accuracy: 0.7688 - val_loss: 0.5132 - val_accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.4470 - accuracy: 0.7812 - val_loss: 0.6296 - val_accuracy: 0.6625\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.4262 - accuracy: 0.7812 - val_loss: 0.5790 - val_accuracy: 0.7125\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.3869 - accuracy: 0.8188 - val_loss: 0.6466 - val_accuracy: 0.6875\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 3s 294ms/step - loss: 0.4507 - accuracy: 0.7812 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 3s 296ms/step - loss: 0.3671 - accuracy: 0.8219 - val_loss: 0.5791 - val_accuracy: 0.7625\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 3s 296ms/step - loss: 0.4156 - accuracy: 0.7844 - val_loss: 0.5578 - val_accuracy: 0.7625\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.3711 - accuracy: 0.8188 - val_loss: 0.5904 - val_accuracy: 0.7625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f0e926697b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(\n",
    "    data, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Augment the training data\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit the data generator on the training set\n",
    "datagen.fit(train_data)\n",
    "\n",
    "# Train the model with augmented data\n",
    "model.fit(\n",
    "    datagen.flow(train_data, train_labels, batch_size=32),\n",
    "    epochs=30,\n",
    "    validation_data=(val_data, val_labels)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5904 - accuracy: 0.7625\n",
      "Test Accuracy: 0.762499988079071\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_data, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output\n",
    "3/3 [==============================] - 0s 45ms/step - loss: 0.5904 - accuracy: 0.7625\n",
    "\n",
    "Test Accuracy: 0.762499988079071"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic model with acceptable accuracy and effort is enough for midterm evaluations.\n",
    "\n",
    "You are encouraged to look into open source libraries for more complicated models to get a good postition on the Kaggle leaderboard!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Happy coding!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
